# Computer Vision: Image Captioning

Authors: [Chataigner Johan](https://github.com/JohanChataigne), [Germon Paul](https://github.com/pgermon), and [Martin Hugo](https://github.com/ScarfZapdos).

This project deals with the problem of **automatically describing the content of images**. It implements several methods of **computer vision** and **natural language processing** in order to generate a **textual description** of a given image as much precise as possible.

## Content of the project

ğŸ“¦image-captioning  
 â”£ ğŸ“‚figures // *contains diamgrams about the performance of the different models*  
 â”£ ğŸ“‚flickr8k // *directory of the flickr8k dataset*  
 â”ƒ â”£ ğŸ“‚annotations  
 â”ƒ â”ƒ â”£ ğŸ“œannotations_image_id_test.csv // *contains captions for the test images*  
 â”ƒ â”ƒ â”£ ğŸ“œannotations_image_id_train.csv  // *contains captions for the train images*    
 â”ƒ â”ƒ â”£ ğŸ“œtestImages.csv // *contains the names of the images in the testing set*   
 â”ƒ â”ƒ â”— ğŸ“œtrainImages.csv  // *contains the names of the images in the training set*   
 â”ƒ â”£ ğŸ“‚images  
 â”ƒ â”ƒ â”£ ğŸ“‚train  
 â”ƒ â”— â”— ğŸ“‚test  
 â”£ ğŸ“‚models // *contains the saved trained models*  
 â”£ ğŸ“œevaluate.ipynb // *Computes the score of the different models*  
 â”£ ğŸ“œinference.py // *Contains inference methods for caption choice*  
 â”£ ğŸ“œmodel_v1_random.ipynb  
 â”£ ğŸ“œmodel_v1_repeat.ipynb  
 â”£ ğŸ“œmodel_v2_random.ipynb  
 â”£ ğŸ“œngram.ipynb  
 â”£ ğŸ“œrandom_caption_dataset.py //  *Random Caption class for models*   
 â”£ ğŸ“œREADME.md  
 â”£ ğŸ“œrepeat_image_dataset.py //  *Repeat Image class for models*  
 â”£ ğŸ“œrequirements.txt  
 â”£ ğŸ“œsetup.py // *To launch once the repository is cloned*   
 â”£ ğŸ“œtext_preprocessing.py // *Preprocessor class*  
 â”— ğŸ“œtransforms.py // *Preprocessing file*  


## Launching the project

In order to launch the project, start by **cloning this repository**.  
**Execute setup.py** to create a working directory that works well with the project.  
Now **you can use the notebooks**.  
